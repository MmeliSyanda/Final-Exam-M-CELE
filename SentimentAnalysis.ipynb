{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMzloy5QbmrOrNkoHJqpxr0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"KkzXxAOcL_FS","executionInfo":{"status":"ok","timestamp":1729167247027,"user_tz":-120,"elapsed":405,"user":{"displayName":"Syanda Mmeli","userId":"04077392860215343822"}}},"outputs":[],"source":[]},{"cell_type":"markdown","source":["**Sentiment Analysis(Employee Feedback)**\n","\n","Step 1 :\n","I would gather textual data that is provided by Employees as Feedback\n","(e.g, tweets, comments, quiestionairess or surveys) about the Two Pot System\n","\n","Step 2:\n","\n","*   Tokenization - I will isolate individual words or phrases, making it easier to analyze the sentiment associated with them. For example, the sentence \"I am not satisfied with this new system\" would be tokenized into [\"I\", \"am\",\"not\", \"satisfied\", \"with\", \"this\", \"new\", \"System\"]. This will allow sentiment analysis models to evaluate each word's contribution to the overall sentiment.\n","\n","\n","*  Removing stop words - this will help reduce noise in the dataset, allowing the model to focus on more informative words that contribute to sentiment. For instance, in the sentence \"I am not satisfied with this new system\", removing stopwords would leave us with [\"satisfied\", \"system\"].\n","\n","\n","* Lowercasing Text : This step ensures that words are treated uniformly. For instance, \"satisfied,\" \"Satisfied,\" and \"SATISFIED\" would all be considered the same word after lowercasing, preventing redundancy in token representation.\n","\n","*   Lemmatization/Stemming\n"," - Stemming: This technique reduces words to their base or root form. For\n","     example, \"running\" becomes \"run\" and \"better\" becomes \"better.\"\n"," - Lemmatization: This method considers the context and converts words to their\n","     base form. For example, \"better\" would be lemmatized to \"good.\"\n","\n","Step 3:\n","Feature Extraction\n","\n","This process involves converting text into numerical formats that can be easily interpreted by machine learning algorithms.\n","\n","1. Bag of Words (BoW)\n"," The Bag of Words model represents text data as a collection of words, disregarding grammar and word order. Each unique word in the text corpus becomes a feature, and the model counts the occurrences of each word in a document.\n","\n"," BoW helps to create a vector representation of text where each feature corresponds to a word from the vocabulary. This is particularly useful for sentiment analysis because it allows models to learn from the frequency of words, which can indicate sentiment (e.g., \"happy\" for positive sentiment and \"sad\" for negative sentiment).\n","\n","2. TF-IDF (Term Frequency-Inverse Document Frequency)\n","Definition: TF-IDF is a statistical measure that evaluates the importance of a word in a document relative to a collection of documents (the corpus). It combines two components:\n","\n","Term Frequency (TF): Measures how frequently a term appears in a document.\n","Inverse Document Frequency (IDF): Measures how important a term is across the entire corpus, reducing the weight of common terms.\n","\n","Step 4\n","\n","Modeling\n","I will then apply machine learning algorithms\n","for sentiment classification, such as the following:\n","• Naive Bayes,\n","• Logistic Regression,\n","• SVM.\n","\n","Step 5\n","Model Evaluation\n","\n","For sentiment analysis and other classification tasks, common performance metrics include accuracy, precision, recall, and the F1 score.I will check for accurracy using these ways to measure measure of how often the sentiment predicted by the model matches the actual sentiment. Also precision will be taken into consideration for indicating how many of the instances predicted as positive are actually positive. High precision is crucial in scenarios where false positives are costly.\n","\n","I will then also Recall forindicating how many actual positive instances were correctly identified by the model. High recall important in situations where missing a positive case is critical.\n","\n","The F1 score will balances both metrics and will be useful if the datasets are imbalanced datasets. This will also provide a single measure of model performance, especially when false positives and false negatives have different costs"],"metadata":{"id":"g8aYOW6INgtb"}}]}